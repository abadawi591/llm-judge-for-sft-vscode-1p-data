// =============================================================================
// DETAILED: Turns WITH tool usage
// =============================================================================
// QUESTION: How does promptTokens grow when tools are used?
//
// EXPECTED:
// - llmCallCount = numRequests (one call per tool + final response)
// - promptGrowth > 0 (tool results add tokens)
// - promptTokensList shows progression: [11317, 15817, 18210, 21934]
// =============================================================================

let timeStart = ago(24h);
let timeEnd = now();

let toolData = 
    AppEvents
    | where TimeGenerated > timeStart and TimeGenerated <= timeEnd
    | where Name == "GitHub.copilot-chat/toolCallDetailsInternal"
    | extend messageId = tostring(Properties["messageId"])
    | extend toolCounts = tostring(Properties["toolCounts"])
    | extend numRequests = toint(Measurements["numRequests"])
    | extend responseType = tostring(Properties["responseType"])
    | where responseType == "success"
    | where toolCounts != "{}"  // HAS TOOLS
    | project messageId, toolCounts, numRequests;

let tokenCalls = 
    AppEvents
    | where TimeGenerated > timeStart and TimeGenerated <= timeEnd
    | where Name == "GitHub.copilot-chat/engine.messages.length"
    | extend message_direction = tostring(Properties["message_direction"])
    | where message_direction == "output"
    | extend messageId = tostring(Properties["headerRequestId"])
    | extend promptTokens = toint(Measurements["promptTokens"])
    | extend completionTokens = toint(Measurements["completionTokens"])
    | project TimeGenerated, messageId, promptTokens, completionTokens
    | order by messageId, TimeGenerated asc;

toolData
| join kind=inner tokenCalls on messageId
| summarize 
    llmCallCount = count(),
    promptTokensList = make_list(promptTokens),
    completionTokensList = make_list(completionTokens),
    minPrompt = min(promptTokens),
    maxPrompt = max(promptTokens)
    by messageId, toolCounts, numRequests
| extend promptGrowth = maxPrompt - minPrompt
| project 
    messageId,
    toolCounts,
    numRequests,
    llmCallCount,
    promptTokensList,
    promptGrowth,
    avgGrowthPerTool = promptGrowth / (numRequests - 1)  // Average tokens per tool result
| order by numRequests desc
| take 30

// =============================================================================
// EXPECTED OUTPUT:
// messageId | toolCounts                    | numRequests | llmCallCount | promptTokensList           | promptGrowth
// ----------|-------------------------------|-------------|--------------|----------------------------|-------------
// abc123    | {"read_file":3}               | 4           | 4            | [10000,15000,20000,25000]  | 15000
// def456    | {"web_search":2,"web_fetch":1}| 4           | 4            | [11317,15817,18210,21934]  | 10617
//
// INTERPRETATION:
// - promptTokensList shows cumulative growth
// - Each tool result adds tokens (visible in the progression)
// - promptGrowth = total tool tokens added in this turn
// =============================================================================

